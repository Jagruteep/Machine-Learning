{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of KRR, Logistic Regression and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagpa\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\jagpa\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('C:/Users/jagpa/ML/ML_Exam/classsification/classification_data2.txt')\n",
    "data = pd.DataFrame(data,index=data[:,0],columns=['area','perimeter','compactness','kernel_length','kernel_width','asym','groove_length','type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary statistics of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>kernel_length</th>\n",
       "      <th>kernel_width</th>\n",
       "      <th>asym</th>\n",
       "      <th>groove_length</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.26</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.88</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.29</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.84</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         area  perimeter  compactness  kernel_length  kernel_width   asym  \\\n",
       "NaN       NaN        NaN          NaN            NaN           NaN    NaN   \n",
       " 15.26  15.26      14.84       0.8710          5.763         3.312  2.221   \n",
       " 14.88  14.88      14.57       0.8811          5.554         3.333  1.018   \n",
       " 14.29  14.29      14.09       0.9050          5.291         3.337  2.699   \n",
       " 13.84  13.84      13.94       0.8955          5.324         3.379  2.259   \n",
       "\n",
       "        groove_length  type  \n",
       "NaN               NaN   NaN  \n",
       " 15.26          5.220   1.0  \n",
       " 14.88          4.956   1.0  \n",
       " 14.29          4.825   1.0  \n",
       " 13.84          4.805   1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping row**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data contains missing values. These values cause errors while handling the data further.I'm dropping row containing missing values (NaN) using dropna() function and then resetting the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#taking care of missing values\n",
    "data=data.dropna()\n",
    "data=data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>kernel_length</th>\n",
       "      <th>kernel_width</th>\n",
       "      <th>asym</th>\n",
       "      <th>groove_length</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   area  perimeter  compactness  kernel_length  kernel_width   asym  \\\n",
       "0  15.26  15.26      14.84       0.8710          5.763         3.312  2.221   \n",
       "1  14.88  14.88      14.57       0.8811          5.554         3.333  1.018   \n",
       "2  14.29  14.29      14.09       0.9050          5.291         3.337  2.699   \n",
       "3  13.84  13.84      13.94       0.8955          5.324         3.379  2.259   \n",
       "4  16.14  16.14      14.99       0.9034          5.658         3.562  1.355   \n",
       "\n",
       "   groove_length  type  \n",
       "0          5.220   1.0  \n",
       "1          4.956   1.0  \n",
       "2          4.825   1.0  \n",
       "3          4.805   1.0  \n",
       "4          5.175   1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 210 entries, 0 to 209\n",
      "Data columns (total 9 columns):\n",
      "index            210 non-null float64\n",
      "area             210 non-null float64\n",
      "perimeter        210 non-null float64\n",
      "compactness      210 non-null float64\n",
      "kernel_length    210 non-null float64\n",
      "kernel_width     210 non-null float64\n",
      "asym             210 non-null float64\n",
      "groove_length    210 non-null float64\n",
      "type             210 non-null float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 14.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>kernel_length</th>\n",
       "      <th>kernel_width</th>\n",
       "      <th>asym</th>\n",
       "      <th>groove_length</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.847524</td>\n",
       "      <td>14.847524</td>\n",
       "      <td>14.559286</td>\n",
       "      <td>0.870999</td>\n",
       "      <td>5.628533</td>\n",
       "      <td>3.258605</td>\n",
       "      <td>3.700201</td>\n",
       "      <td>5.408071</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.909699</td>\n",
       "      <td>2.909699</td>\n",
       "      <td>1.305959</td>\n",
       "      <td>0.023629</td>\n",
       "      <td>0.443063</td>\n",
       "      <td>0.377714</td>\n",
       "      <td>1.503557</td>\n",
       "      <td>0.491480</td>\n",
       "      <td>0.818448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.590000</td>\n",
       "      <td>10.590000</td>\n",
       "      <td>12.410000</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>4.899000</td>\n",
       "      <td>2.630000</td>\n",
       "      <td>0.765100</td>\n",
       "      <td>4.519000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.270000</td>\n",
       "      <td>12.270000</td>\n",
       "      <td>13.450000</td>\n",
       "      <td>0.856900</td>\n",
       "      <td>5.262250</td>\n",
       "      <td>2.944000</td>\n",
       "      <td>2.561500</td>\n",
       "      <td>5.045000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.355000</td>\n",
       "      <td>14.355000</td>\n",
       "      <td>14.320000</td>\n",
       "      <td>0.873450</td>\n",
       "      <td>5.523500</td>\n",
       "      <td>3.237000</td>\n",
       "      <td>3.599000</td>\n",
       "      <td>5.223000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.305000</td>\n",
       "      <td>17.305000</td>\n",
       "      <td>15.715000</td>\n",
       "      <td>0.887775</td>\n",
       "      <td>5.979750</td>\n",
       "      <td>3.561750</td>\n",
       "      <td>4.768750</td>\n",
       "      <td>5.877000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.180000</td>\n",
       "      <td>21.180000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>0.918300</td>\n",
       "      <td>6.675000</td>\n",
       "      <td>4.033000</td>\n",
       "      <td>8.456000</td>\n",
       "      <td>6.550000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index        area   perimeter  compactness  kernel_length  \\\n",
       "count  210.000000  210.000000  210.000000   210.000000     210.000000   \n",
       "mean    14.847524   14.847524   14.559286     0.870999       5.628533   \n",
       "std      2.909699    2.909699    1.305959     0.023629       0.443063   \n",
       "min     10.590000   10.590000   12.410000     0.808100       4.899000   \n",
       "25%     12.270000   12.270000   13.450000     0.856900       5.262250   \n",
       "50%     14.355000   14.355000   14.320000     0.873450       5.523500   \n",
       "75%     17.305000   17.305000   15.715000     0.887775       5.979750   \n",
       "max     21.180000   21.180000   17.250000     0.918300       6.675000   \n",
       "\n",
       "       kernel_width        asym  groove_length        type  \n",
       "count    210.000000  210.000000     210.000000  210.000000  \n",
       "mean       3.258605    3.700201       5.408071    2.000000  \n",
       "std        0.377714    1.503557       0.491480    0.818448  \n",
       "min        2.630000    0.765100       4.519000    1.000000  \n",
       "25%        2.944000    2.561500       5.045000    1.000000  \n",
       "50%        3.237000    3.599000       5.223000    2.000000  \n",
       "75%        3.561750    4.768750       5.877000    3.000000  \n",
       "max        4.033000    8.456000       6.550000    3.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separating data into Features (X) and Target(y).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop(['type'],axis=1).values\n",
    "y = data['type'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting all the attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Principal Component Analysis (PCA) does the analysis of data to identify patterns and finding patterns to reduce the dimensions of thedataset with minimal loss of information. Here I'm using PCA to covert attributes into 2-dimensions and plot all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scatter Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEJvHwjsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x260d2502208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmp_pca = PCA(n_components=2) # 2 PCA components;\n",
    "arr_pca = cmp_pca.fit_transform(X)\n",
    "plt.scatter(arr_pca[:,0],arr_pca[:,1],c='C')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histogram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhl6SmvtfUJ0Uql1Jl54AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x260d286eda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy.random import normal\n",
    "arr_pca = normal(size=1000)\n",
    "plt.hist(arr_pca)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x260d289dda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = pd.concat([data['area'], data['perimeter']], axis =1)\n",
    "plt.hist(q)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correlation values between attribute columns are shown belown in Correlation Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>kernel_length</th>\n",
       "      <th>kernel_width</th>\n",
       "      <th>asym</th>\n",
       "      <th>groove_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994341</td>\n",
       "      <td>0.608288</td>\n",
       "      <td>0.949985</td>\n",
       "      <td>0.970771</td>\n",
       "      <td>-0.229572</td>\n",
       "      <td>0.863693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994341</td>\n",
       "      <td>0.608288</td>\n",
       "      <td>0.949985</td>\n",
       "      <td>0.970771</td>\n",
       "      <td>-0.229572</td>\n",
       "      <td>0.863693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter</th>\n",
       "      <td>0.994341</td>\n",
       "      <td>0.994341</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.529244</td>\n",
       "      <td>0.972422</td>\n",
       "      <td>0.944829</td>\n",
       "      <td>-0.217340</td>\n",
       "      <td>0.890784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness</th>\n",
       "      <td>0.608288</td>\n",
       "      <td>0.608288</td>\n",
       "      <td>0.529244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.367915</td>\n",
       "      <td>0.761635</td>\n",
       "      <td>-0.331471</td>\n",
       "      <td>0.226825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kernel_length</th>\n",
       "      <td>0.949985</td>\n",
       "      <td>0.949985</td>\n",
       "      <td>0.972422</td>\n",
       "      <td>0.367915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860415</td>\n",
       "      <td>-0.171562</td>\n",
       "      <td>0.932806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kernel_width</th>\n",
       "      <td>0.970771</td>\n",
       "      <td>0.970771</td>\n",
       "      <td>0.944829</td>\n",
       "      <td>0.761635</td>\n",
       "      <td>0.860415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.258037</td>\n",
       "      <td>0.749131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asym</th>\n",
       "      <td>-0.229572</td>\n",
       "      <td>-0.229572</td>\n",
       "      <td>-0.217340</td>\n",
       "      <td>-0.331471</td>\n",
       "      <td>-0.171562</td>\n",
       "      <td>-0.258037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>groove_length</th>\n",
       "      <td>0.863693</td>\n",
       "      <td>0.863693</td>\n",
       "      <td>0.890784</td>\n",
       "      <td>0.226825</td>\n",
       "      <td>0.932806</td>\n",
       "      <td>0.749131</td>\n",
       "      <td>-0.011079</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  index      area  perimeter  compactness  kernel_length  \\\n",
       "index          1.000000  1.000000   0.994341     0.608288       0.949985   \n",
       "area           1.000000  1.000000   0.994341     0.608288       0.949985   \n",
       "perimeter      0.994341  0.994341   1.000000     0.529244       0.972422   \n",
       "compactness    0.608288  0.608288   0.529244     1.000000       0.367915   \n",
       "kernel_length  0.949985  0.949985   0.972422     0.367915       1.000000   \n",
       "kernel_width   0.970771  0.970771   0.944829     0.761635       0.860415   \n",
       "asym          -0.229572 -0.229572  -0.217340    -0.331471      -0.171562   \n",
       "groove_length  0.863693  0.863693   0.890784     0.226825       0.932806   \n",
       "\n",
       "               kernel_width      asym  groove_length  \n",
       "index              0.970771 -0.229572       0.863693  \n",
       "area               0.970771 -0.229572       0.863693  \n",
       "perimeter          0.944829 -0.217340       0.890784  \n",
       "compactness        0.761635 -0.331471       0.226825  \n",
       "kernel_length      0.860415 -0.171562       0.932806  \n",
       "kernel_width       1.000000 -0.258037       0.749131  \n",
       "asym              -0.258037  1.000000      -0.011079  \n",
       "groove_length      0.749131 -0.011079       1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation between values\n",
    "data2 = data.drop('type',axis=1)\n",
    "corr_mx = data2.corr()\n",
    "corr_mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm splitting dataset into training and testing set by 80% i.e. 80% train set and 20% test set. Training set contains a known output and model learns on trained data in order to be generalized to other data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data\n",
      "(168, 8)\n",
      "Shape of testing data\n",
      "(42, 8)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=1)\n",
    "print('Shape of training data')\n",
    "print(X_train.shape)\n",
    "print('Shape of testing data')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. Logistic regression builds on the basic formula for linear regression (a), simplified to (b), which produces a predicted target value for an input vector.\n",
    "\n",
    "(a) y(x) = w0+ w1(x1) + ... + wn(xn)\n",
    "\n",
    "(b) y(x) = w'(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegressionModel = linear_model.LogisticRegression()\n",
    "LogisticRegressionModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test data : 0.97619047619\n"
     ]
    }
   ],
   "source": [
    "LogisticRegScore = LogisticRegressionModel.score(X_test,y_test)\n",
    "print('Score on test data :',LogisticRegScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on train data : 0.916666666667\n"
     ]
    }
   ],
   "source": [
    "LogisticRegScoreTrain = LogisticRegressionModel.score(X_train,y_train)\n",
    "print('Score on train data :',LogisticRegScoreTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Error of the Logistic Regression model is: \n",
      "[[19  1  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "logistic_model_predictions = LogisticRegressionModel.predict(X_test)\n",
    "logistic_error = confusion_matrix(y_true=y_test, y_pred=logistic_model_predictions, labels=None, sample_weight=None)\n",
    "print('The Error of the Logistic Regression model is: ')\n",
    "print(logistic_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernalized Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use plain Ridge Regression to minimize L2-regularized least-square error. Kernelized Ridge Regression has the same objective, but use a substitution to rewrite the function in terms of , so that predictions can be made without needing to compute directly.\n",
    "A few choices for the kernel are\n",
    "\n",
    "(a)Linear / Identity Kernel : K(X,X) = X X\n",
    "\n",
    "(b)Polynomial Kernel : K(X,X) = ( X X + r)M \n",
    "\n",
    "(c)RBF / Gaussian Kernel : K(X,X) = exp [ - (|| X - X ||2) / 22 ]\n",
    "\n",
    "**Cross-Validation** :\n",
    "It is a model validation technique for evaluating how the outcomes of a statistical analysis will generalize to an independent data set. Mainly used in backgrounds where the objective is forecast and one wants to estimate how accurately a model will accomplish in practice. The goal of cross-validation is to term a data set to test the model in the training phase (i.e. validation data set) in order to limit problems like overfitting, and get an insight on how the model will generalize to an independent data set.\n",
    "\n",
    "\n",
    "**GridSearchCV** :\n",
    "Scikit-learns GridSearchCV performs k-fold cross validation and searches for a best parameters across a set of parameters. Here I'm using 5-fold cross validation for hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=1, coef0=1, degree=None, gamma=None, kernel='linear',\n",
       "      kernel_params=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRR_linear=KernelRidge(kernel='linear', gamma=None, degree=None, coef0=1, kernel_params=None, alpha=1)\n",
    "KRR_linear.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5052374 ,  3.14073854,  1.57054248,  2.20458318,  1.49524617,\n",
       "        1.91870254,  1.23108423,  2.66643771,  2.04278533,  2.75370438,\n",
       "        2.15481514,  0.86919645,  1.47553628,  0.67106418,  0.9470027 ,\n",
       "        3.16372088,  3.04370507,  1.42631499,  1.72194126,  1.53784171,\n",
       "        1.22473397,  1.34400707,  2.01128079,  2.69551771,  1.95456783,\n",
       "        3.09660846,  1.24849069,  3.29396408,  1.79579404,  1.78274563,\n",
       "        1.43869845,  1.79686211,  1.73526031,  1.40437377,  1.7818201 ,\n",
       "        1.64951075,  2.74833338,  1.6937078 ,  1.44840879,  2.34297151,\n",
       "        1.48728789,  2.63219737])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=KRR_linear.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 error for linear kernel : 0.732248875723\n"
     ]
    }
   ],
   "source": [
    "r2_error1 = r2_score(y_true=y_test, y_pred=y_pred)\n",
    "print('R^2 error for linear kernel :',r2_error1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test data : 0.732248875723\n"
     ]
    }
   ],
   "source": [
    "print('Score on test data :',KRR_linear.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on train data : 0.633851799365\n"
     ]
    }
   ],
   "source": [
    "print('Score on train data :',KRR_linear.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polynomial Kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KernelRidge(alpha=1, coef0=1, degree=3, gamma=1, kernel='polynomial',\n",
       "      kernel_params=None),\n",
       "       fit_params={}, iid=True, n_jobs=1, param_grid={'degree': [2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRR_polynomial= GridSearchCV(KernelRidge(kernel=\"polynomial\", gamma=1, coef0=1), cv=5, param_grid={\"degree\":[2,3,4]})\n",
    "KRR_polynomial.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.30962284,  3.37398694,  1.19752929,  2.30112428,  1.40606989,\n",
       "        2.34539598,  0.88434143,  2.63532931,  2.05337793,  3.09396025,\n",
       "        1.71956639,  0.93532035,  1.29781521,  0.84044922,  0.89421994,\n",
       "        3.47443568,  3.41802903,  1.11331712,  1.40537408,  1.2598908 ,\n",
       "        1.06911601,  1.07078225,  1.8849076 ,  2.9589795 ,  1.80618221,\n",
       "        3.32336356,  1.06917497,  3.67395659,  1.48982066,  2.0504868 ,\n",
       "        1.91584054,  2.18193851,  1.86543096,  1.09633405,  1.92404878,\n",
       "        1.8874245 ,  2.86034932,  2.02407664,  1.19186227,  2.51715612,\n",
       "        1.44643873,  2.62414818])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=KRR_polynomial.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6898034275998355"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRR_polynomial.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'degree': 2}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRR_polynomial.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='rbf',\n",
       "      kernel_params=None),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.1, 0.5, 1, 2, 4]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRR_gaussian= GridSearchCV(KernelRidge(kernel=\"rbf\"), cv=5, param_grid={\"gamma\":[ 0.1, 0.5, 1, 2, 4]})\n",
    "KRR_gaussian.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.1882059 ,  2.34261009,  1.37249802,  2.6578105 ,  1.37423523,\n",
       "        1.61320756,  0.99065665,  2.773754  ,  2.65243904,  3.03203517,\n",
       "        1.90093714,  1.03978623,  1.13564109,  0.80124957,  1.57193623,\n",
       "        2.9883227 ,  2.83332532,  1.00287919,  1.13317253,  1.09516972,\n",
       "        1.12383935,  1.4008979 ,  1.96868677,  2.70966179,  1.33860893,\n",
       "        3.21135868,  0.93285313,  2.91587875,  1.51862095,  2.03259141,\n",
       "        1.96385096,  2.04401751,  1.72399749,  1.01358187,  1.52979076,\n",
       "        1.90925269,  3.0384815 ,  1.31895557,  1.83640638,  2.61322975,\n",
       "        2.27895566,  3.10389553])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=KRR_gaussian.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6814936166898518"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRR_gaussian.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KRR_gaussian.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hard Margin SVM using rbf kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10000000000.0, cache_size=3000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1.5, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=False,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "hard_svm1 = svm.SVC(C =1e10,kernel=\"rbf\",gamma =1.5,shrinking=False,cache_size=3000)\n",
    "hard_svm1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y prediction : [ 1.  3.  1.  3.  1.  2.  1.  3.  3.  3.  2.  1.  1.  1.  1.  3.  3.  1.\n",
      "  1.  1.  1.  2.  2.  3.  1.  3.  1.  3.  1.  2.  2.  2.  2.  1.  3.  2.\n",
      "  3.  2.  3.  3.  3.  3.]\n",
      "Score on test set : 0.904761904762\n",
      "Score on train set : 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred= hard_svm1.predict(X_test)\n",
    "print('y prediction :',y_pred)\n",
    "print('Score on test set :',hard_svm1.score(X_test,y_test))\n",
    "print('Score on train set :',hard_svm1.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Error of the Logistic Regression model is: \n",
      "[[16  1  3]\n",
      " [ 0  9  0]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=hard_svm1.predict(X_test)\n",
    "svm_error = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=None, sample_weight=None)\n",
    "print('The Error of the Logistic Regression model is: ')\n",
    "print(svm_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hard Margin SVM using linear kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100000, cache_size=3000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=False,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_svm2 = svm.SVC(C =100000,kernel=\"linear\",gamma =1,shrinking=False,cache_size=3000)\n",
    "hard_svm2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y prediction : [ 1.  3.  1.  3.  1.  2.  1.  3.  1.  3.  2.  1.  1.  1.  1.  3.  3.  1.\n",
      "  1.  1.  1.  1.  2.  3.  1.  3.  1.  3.  1.  2.  2.  2.  2.  1.  1.  2.\n",
      "  3.  2.  1.  3.  1.  3.]\n",
      "Score on test set : 0.97619047619\n",
      "Score on train set : 0.982142857143\n"
     ]
    }
   ],
   "source": [
    "y_pred= hard_svm2.predict(X_test)\n",
    "print('y prediction :',y_pred)\n",
    "print('Score on test set :',hard_svm2.score(X_test,y_test))\n",
    "print('Score on train set :',hard_svm2.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Error of linear kernel is: \n",
      "[[20  0  0]\n",
      " [ 0  9  0]\n",
      " [ 1  0 12]]\n"
     ]
    }
   ],
   "source": [
    "svm_error2 = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=None, sample_weight=None)\n",
    "print('The Error of linear kernel is: ')\n",
    "print(svm_error2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hard Margin SVM using polynomial kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10000, cache_size=3000, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=False,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_svm3 = svm.SVC(C =10000,kernel=\"poly\",gamma =1,shrinking=False,cache_size=3000)\n",
    "hard_svm3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y prediction : [ 1.  3.  1.  3.  1.  2.  1.  3.  3.  3.  2.  1.  1.  1.  1.  3.  3.  1.\n",
      "  1.  1.  1.  1.  2.  3.  1.  3.  1.  3.  1.  2.  2.  2.  2.  1.  3.  2.\n",
      "  3.  2.  1.  3.  1.  3.]\n",
      "Score on test set : 0.97619047619\n",
      "Score on train set : 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred= hard_svm3.predict(X_test)\n",
    "print('y prediction :',y_pred)\n",
    "print('Score on test set :',hard_svm3.score(X_test,y_test))\n",
    "print('Score on train set :',hard_svm3.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Error of polynomial kernel is: \n",
      "[[19  0  1]\n",
      " [ 0  9  0]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "svm_error3 = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=None, sample_weight=None)\n",
    "print('The Error of polynomial kernel is: ')\n",
    "print(svm_error3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Soft Margin SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y prediction : [ 1.  3.  2.  3.  1.  2.  1.  3.  3.  3.  2.  1.  1.  1.  1.  3.  3.  1.\n",
      "  1.  1.  1.  1.  2.  3.  1.  3.  1.  3.  1.  2.  2.  2.  2.  1.  1.  2.\n",
      "  3.  2.  1.  3.  3.  3.]\n",
      "score on test data for 0.1 : 0.952380952381\n",
      "score on train data for 0.1 : 0.916666666667\n",
      "confusion_mx_error for 0.1\n",
      "[[18  1  1]\n",
      " [ 0  9  0]\n",
      " [ 0  0 13]]\n",
      "\n",
      "\n",
      "y prediction : [ 1.  3.  2.  3.  1.  2.  1.  3.  3.  3.  2.  1.  1.  1.  1.  3.  3.  1.\n",
      "  1.  1.  1.  1.  2.  3.  1.  3.  1.  3.  1.  2.  2.  2.  2.  1.  1.  2.\n",
      "  3.  2.  1.  3.  3.  3.]\n",
      "score on test data for 0.5 : 0.952380952381\n",
      "score on train data for 0.5 : 0.916666666667\n",
      "confusion_mx_error for 0.5\n",
      "[[18  1  1]\n",
      " [ 0  9  0]\n",
      " [ 0  0 13]]\n",
      "\n",
      "\n",
      "y prediction : [ 1.  3.  2.  3.  1.  2.  1.  3.  3.  3.  2.  1.  1.  1.  1.  3.  3.  1.\n",
      "  1.  1.  1.  1.  2.  3.  1.  3.  1.  3.  1.  2.  2.  2.  2.  1.  1.  2.\n",
      "  3.  2.  1.  3.  3.  3.]\n",
      "score on test data for 1 : 0.952380952381\n",
      "score on train data for 1 : 0.916666666667\n",
      "confusion_mx_error for 1\n",
      "[[18  1  1]\n",
      " [ 0  9  0]\n",
      " [ 0  0 13]]\n",
      "\n",
      "\n",
      "y prediction : [ 1.  3.  2.  3.  1.  2.  1.  3.  3.  3.  2.  1.  1.  1.  1.  3.  3.  1.\n",
      "  1.  1.  1.  1.  2.  3.  1.  3.  1.  3.  1.  2.  2.  2.  2.  1.  1.  2.\n",
      "  3.  2.  1.  3.  3.  3.]\n",
      "score on test data for 2 : 0.952380952381\n",
      "score on train data for 2 : 0.916666666667\n",
      "confusion_mx_error for 2\n",
      "[[18  1  1]\n",
      " [ 0  9  0]\n",
      " [ 0  0 13]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coef0 = [0.1, 0.5, 1, 2, 5]\n",
    "for i in range(4) :\n",
    "    soft_svm = svm.SVC(C = 1,coef0=coef0[i])\n",
    "    soft_svm.fit(X_train,y_train)\n",
    "    y_pred= soft_svm.predict(X_test)\n",
    "    print('y prediction :',y_pred)\n",
    "    print('score on test data for', coef0[i],':',soft_svm.score(X_test,y_test))\n",
    "    print('score on train data for', coef0[i],':',soft_svm.score(X_train,y_train))\n",
    "    conf_mx = confusion_matrix(y_test,y_pred)\n",
    "    print('confusion_mx_error for',coef0[i])\n",
    "    print(conf_mx)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Soft Margin SVM using cross validation(RBF)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for rbf : 0.9285714285714286\n",
      "best parameters : {'C': 100, 'gamma': 0.1, 'kernel': 'rbf', 'max_iter': 5000}\n",
      "confusion_mx_error:\n",
      " [[18  1  1]\n",
      " [ 0  9  0]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "soft_svm2_rbf = svm.SVC()\n",
    "soft_svm2_rbf = GridSearchCV(estimator=soft_svm2_rbf, param_grid={'kernel': ['rbf'], 'C': [1, 100, 1000],  'gamma': [0.1, 0.5, 1, 2, 5], 'max_iter':[5000]}, cv=5, refit=True, scoring='accuracy')\n",
    "soft_svm2_rbf.fit(X_train, y_train)\n",
    "y_pred2 = soft_svm2_rbf.predict(X_test)\n",
    "y_pred2\n",
    "print('score for rbf :',soft_svm2_rbf.best_score_)\n",
    "print('best parameters :',soft_svm2_rbf.best_params_)\n",
    "conf_mx = confusion_matrix(y_test,y_pred)\n",
    "print('confusion_mx_error:\\n',conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Soft Margin SVM using cross validation(Poly)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for polynomial : 0.9047619047619048\n",
      "best parameters : {'C': 1, 'gamma': 0.5, 'kernel': 'poly', 'max_iter': 5000}\n",
      "confusion_mx_error:\n",
      " [[18  1  1]\n",
      " [ 0  9  0]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "soft_svm2_poly = svm.SVC()\n",
    "soft_svm2_poly = GridSearchCV(estimator=soft_svm2_poly, param_grid={'kernel': ['poly'], 'C': [1, 100, 1000],  'gamma': [0.1, 0.5, 1, 2, 5], 'max_iter':[5000]}, cv=5, refit=True, scoring='accuracy')\n",
    "soft_svm2_poly.fit(X_train, y_train)\n",
    "y_pred2 = soft_svm2_poly.predict(X_test)\n",
    "y_pred2\n",
    "print('score for polynomial :',soft_svm2_poly.best_score_)\n",
    "print('best parameters :',soft_svm2_poly.best_params_)\n",
    "conf_mx = confusion_matrix(y_test,y_pred)\n",
    "print('confusion_mx_error:\\n',conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Soft Margin SVM using cross validation(Linear)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for linear : 0.9404761904761905\n",
      "best parameters : {'C': 100, 'kernel': 'linear', 'max_iter': 5000}\n",
      "confusion_mx_error:\n",
      " [[18  1  1]\n",
      " [ 0  9  0]\n",
      " [ 0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "soft_svm2_lnr = svm.SVC()\n",
    "soft_svm2_lnr = GridSearchCV(estimator=soft_svm2_lnr, param_grid={'kernel': ['linear'], 'C': [1, 100, 1000], 'max_iter':[5000]}, cv=5, refit=True, scoring='accuracy')\n",
    "soft_svm2_lnr.fit(X_train, y_train)\n",
    "y_pred2 = soft_svm2_lnr.predict(X_test)\n",
    "y_pred2\n",
    "print('score for linear :',soft_svm2_lnr.best_score_)\n",
    "print('best parameters :',soft_svm2_lnr.best_params_)\n",
    "conf_mx = confusion_matrix(y_test,y_pred)\n",
    "print('confusion_mx_error:\\n',conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance measures of all the models given below :**\n",
    "    \n",
    "**Logistic Regression Model** :  0.97619047619\n",
    "\n",
    "**Kernalized Ridge Regression** \n",
    "\n",
    "Linear Kernel :  0.732248875723, Polynomial Kernel : 0.6898034276003652, Gaussian Kernel : 0.6814936166898518\n",
    "\n",
    "**SVM**\n",
    "\n",
    "Hard SVM : rbf : 0.904761904762, liear : 0.97619047619 , poly :  0.97619047619\n",
    "\n",
    "\n",
    "Soft SVM : 0.952380952381 for all coefficients\n",
    "\n",
    "Soft SVM using CV : rbf :0.9285714285714286 for coef=0.1,  poly: 0.9047619047619048 for coef=0.5, linear:0.9404761904761905\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Model and Polynomial Kernel of Hard Margin SVM give best performances, but Hard margin SVM using polynomial kernel is best model only if C is 10000 otherwise Logistic Regression model is the best model for the data amongst all other models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
